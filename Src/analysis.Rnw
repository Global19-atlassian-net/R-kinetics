\documentclass[letterpaper,12pt]{article}

%%%%%%%%%%%%%%%%%%%%%%%% Standard Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyvrb}
\usepackage{comment}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{subfig}
%%%%%%%%%%%%%%%%%%%%%%%% Adapted from Sweave %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DefineVerbatimEnvironment{Rcode}{Verbatim}{fontshape=sl, frame=single, 
  framesep=2mm, fontsize=\small, baselinestretch=.5}

%%%%%%%%%%%%%%%%%%%%%%%% Page and Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\addtolength{\oddsidemargin}{-0.875in}
\addtolength{\topmargin}{-0.875in}
\addtolength{\textwidth}{1.75in}
\addtolength{\textheight}{1.75in}

\renewcommand{\topfraction}{0.9}        % max fraction of floats at top
\renewcommand{\bottomfraction}{0.8}     % max fraction of floats at bottom

% Parameters for TEXT pages (not float pages):
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}             % 2 may work better
\setcounter{dbltopnumber}{2}            % for 2-column pages
\renewcommand{\dbltopfraction}{0.9}     % fit big float above 2-col. text
\renewcommand{\textfraction}{0.07}      % allow minimal text w. figs

% Parameters for FLOAT pages (not text pages):
\renewcommand{\floatpagefraction}{0.7}          % require fuller float pages

% N.B.: floatpagefraction MUST be less than topfraction !!
\renewcommand{\dblfloatpagefraction}{0.7}       % require fuller float pages


\def\argmax{\operatornamewithlimits{arg\,max}}
\def\argmin{\operatornamewithlimits{arg\,min}}

\definecolor{myblue}{rgb}{0.25, 0, 0.75}
\definecolor{mygold}{rgb}{1,0.8,0.2}
\definecolor{gray}{rgb}{0.5, 0.5, 0.5}

\newcommand{\myurl}[1]{\href{http://#1}{\textcolor{gray}{\texttt{#1}}}}
\newcommand{\myem}[1]{\structure{#1}}
\newcommand{\myurlshort}[2]{\href{http://#1}{\textcolor{gray}{\textsf{#2}}}}

\newcommand{\RPackage}[1]{\textcolor{gray}{\textsf{#1}}}
\newcommand{\PL}[1]{\texttt{#1}}
\newcommand{\RCode}[1]{\texttt{#1}}
\newcommand{\RFunction}[1]{\textsf{#1}}
\newcommand{\RClass}[1]{\textcolor{mygold}{\textsf{#1}}}
\newcommand{\BIOCfunction}[1]{\textcolor{orange}{#1}}

%%%%%%%%%%%%%%%%%%%%%%% options for sweave %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\SweaveOpts{prefix.string=plots/plots, eps=FALSE, echo=FALSE}

%%%%%%%%%%%%%%%%%%%%%%% headers and footers %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy} 
\renewcommand{\footrulewidth}{\headrulewidth}

%%%%%%%%%%%%%%%%%%%%%%% bibliography %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{plainnat}

%%%%%%%%%%%%%%%%%%%%%%% opening %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{DNA-Modification Detection with SMRT-Sequencing using R}
\author{Pacific Biosciences}

\begin{document}
\maketitle
\tableofcontents
\begin{abstract}
  This documents describes a programing interface to Pacific
  Biosciences cmp.h5 files. These files provide additional data beyond
  basecalls and quality values obtained during a sequencing run. These
  data can be used to discover base modifications, e.g., DNA
  methylation events. In addition to demonstrating the detection of
  DNA methylation in a two-sample statistical testing context, we
  present an \PL{R} API for generally extracting data from PacBio HDF5
  files. 
\end{abstract}

\section{Introduction}
Base modifications are important in understanding a variety of
biological processes such as gene expression, host-pathogen
interactions, DNA damage and DNA repair. Single-Molecule Real-Time
(SMRT) sequencing has the potential to revolutionize the study of base
modifications through direct detection on unamplified source material.
Traditionally, it has been a challenge to study the wide variety of
modifications that are seen in nature.  Most high throughput
techniques focus on cytosine methylation -- made accessible through
bisulfite treatment when sequencing or PCR techniques are used to
detect the methylation at a single-base resolution. SMRT-sequencing,
in contrast, does not require genetic alterations to the source
material in order to view base modifications. Instead, measurements of
the kinetics of base addition are made during the normal course of
sequencing. These kinetic measurements present characteristic patterns
in response to a wide variety of base modifications.  As a result of
this relatively simple mechanism to detect base modifications, it is
now possible to study more than just 5-methylcytosine in a
high-throughput fashion.  Bacterial modifications such as
6-methyladenine, or more recently re-discovered modifications such as
5-hydroxymethylcytosine, are accessible to study using a single
sequencing method -- and even a single sequencing run -- on the PacBio
RS. As the technology advances, direct detection of RNA modifications
will also become possible. As our understanding of kinetic information
grows, the analysis of base modifications using SMRT technology will
continue to become easier and faster, making accessible a rich new
frontier of scientific study.

In this document we attempt to demonstrate how to perform DNA
modification detection using the suite of R packages developed and
used at Pacific Biosciences. These APIs provide the developer with
low-level access to all information collected during a sequencing
run. This document attempts to serve two purposes (1) to demonstrate
the use of the \RPackage{pbh5} R package to access low-level data
produced during a SMRT-sequencing run and (2) to provide a starting
point for users to conduct their own kinetic analysis.

\subsection{R Packages/System Requirements}
In this analysis we will make heavey use of the \RPackage{pbh5} and
\RPackage{pbutils} R packages. In addition, the \RPackage{pbh5}
package depends on the \RPackage{h5r} package. Finally, we will also
make use of the \RPackage{ggplot2} and \RPackage{xtable} packages
available on CRAN. All of the analysis conducted here can be performed
using the \RPackage{pbh5} package exclusively, however, the code to
execute this document depends on the afformentioned packages.

<<echo=TRUE, results=hide>>=
require(pbh5)
require(pbls)
require(xtable)
require(ggplot2)
source("utils.R")
@ 
In addition to R package requirements, this document requires a
system with approximately 3-4 Gigabytes of memory and a recent version
of R, i.e., R-2-12. Finally, this document is a ``vignette'', i.e.,
the code and text is all contained in analysis.Rnw, the code extracted
can be found in analysis.R. To ``run'' this document, the user can
perform the following from the top-level directory:
\begin{verbatim}
  make analysis-build
\end{verbatim}
This will download the data into the Data directory and then run the
analysis.Rnw document.

\subsection{Experimental Setup}
This experiment focuses on two different sources of input DNA (1)
Synthetically methylated DNA with a few site-specific modifications
per template and (2) DNA library data from lambda phage. For the
synthetically modified data, we have a 5 identical (from a nucleotide
sequence perspective) templates. Four of these templates have
modifications at particular sites. One is a control template which
will be used in comparison to each treatment template.
<<echo=FALSE,results=tex>>=
makeSummaryTable("Synthetic", caption = "Summary of synthetically methylated datasets used in this document.",
                 label = "tbl:synthetic")
@ 

For the lambda data set, we have both DAM+ and DAM- preparations as
well as whole-genome amplifications for both of the DAM+ and DAM-
preparations. The DAM or DNA methyl-transferase specifically
methylates the adenine basee of the GATC motif in
lambda. Additionally, lambda contains methyl-transferases for other
motifs - these modified sites we could potentially see when comparing
the DAM-\_native to the DAM-\_WGA conditions.
<<echo=FALSE,results=tex>>=
makeSummaryTable("Lambda", caption = "Summary of lambda datasets used in this document.",
                 label = "tbl:lambda")
@ 

\section{Exploring the Data}
As described above, SMRT-Sequecing provides a rich set of information
beyond that of traditional sequencing platforms. Specifically, here we
focus on information about the kinetic behavior of the polymerase at
specific positions in the reference sequence. We first examine
high-level summaries of the data, such as yield, read length, and
accuracy. We will focus on the Lambda data for some of the major
exploratory work because it provides a larger number of sequencing
contexts to investigate. First, we describe some of the major
components of the \PL{R} API which we will use throughout this
document to analyze the two different modification datasets.

\subsection{Working with the Compare H5 File}
The {\em cmp.h5} file (pronounced comp H5 or compare H5) provides a
rich set of data resulting from the alignment of PacBio data to a
reference sequence. The cmp.h5 file may contain one or more movies
(sequencing runs) and contains all of the alignments for that movie's
reads to a reference fasta file.
\begin{figure}
  \centering
  \includegraphics{cmpH5HDF5View}
  \caption{{\em cmp.h5 Structure} - A screenshot of the cmp.h5 file
    structure as seen through the ``hdfview'' tool provided by the
    hdfgroup.org. PacBio cmp.h5 files provide a wealth of additional
    information about the sequencing run. Broadly speaking, HDF5 files
    can be thought of as a file system for your data -- allowing one
    to organize both metada and experimental results in consistent
    structures.  }
\end{figure}
<<echo=TRUE>>=
cmpH5 <- PacBioCmpH5("../Data/Lambda/6mA_dam+_native/data/aligned_reads.cmp.h5") 
cmpH5
@ 
The core of the file is represented by the ``AlnIndex'' and the
corresponding ``AlnArray'' datasets. Alignments, QualityValues, and
kinetic data are stored at the ``refGroup/alnGroup'' level of the
hierarchy, e.g.,
<<echo=TRUE>>=
group <- "ref000001/m110818_122604_42141_c100129202555500000315043109121114_s1_p0"
g <- getH5Group(cmpH5, group)
ls(g)
@ 
Each of these datasets contain all of the alignment related data for a
given ``alignment group'' which tends to be a movie. The alignments
are packed together in a compact format and the ``AlnIndex'' contains
the relevant information on how to extract a particular alignment. The
incredibly long ``basename'' portion of the path represents the movie
name, whereas the ``dirname'' portion represents the reference
sequence. The mapping between the canonical ``ref000001'' and the name
in the fasta file can be found using the \RFunction{refGroup}
function. For our work, the most pertinent datasets are: AlnArray, IPD
(inter-pulse duration), and PulseWidth.

As mentioned above, all of the alignments in the file are stored in a
global alignment index. In addition to providing summary statisitics
about alignments, e.g., the number of mismatches, deletions, etc., the
index provides the offsets into the alignment datasets for fast random
access to alignments.
<<echo=TRUE>>=
head(alnIndex(cmpH5), 2)
@ 
In general, these details can be ignored and users can interact with
the file via the accessor API functions. For instance, to access an
alignment:
<<echo=TRUE>>=
alns <- getAlignments(cmpH5, idx = c(1, 200, 3))
lapply(alns, head, n = 2)
@ 
The API provides a large set of functions with the above signature,
i.e., \RCode{cmpH5} and \RCode{idx}, where \RCode{idx} is an index
vector which must contain values between 1 and \RCode{nrow(cmpH5)}
inclusive. These naturally refer to the rows in the
\RCode{alnIndex(cmpH5)}. In addition to \RCode{getAlignments}, other
useful functions include: \RCode{getIPD}, \RCode{getPulseWidth}, and
\RCode{getQualityValue}.  

To get more information on the cmp.h5 file format refer to:
www.pacbiodevnet.com/Learn/Documentation. Also, to get help on the
pbh5 package, try \RCode{?pbh5}. In the remainder of the document, we
will typically hide the code to not disrupt the document flow. As
mentioned above, all of the code can be found in either analysis.Rnw
or analysis.R

\subsection{Visualizing Kinetic Properties of the System}
In this section, we visualize pulse width and IPD (inter-pulse
duration) distributions. These two, especially IPD, represent the
primary source of data informing possible base modifications. In
Figures \ref{fig:ipdcartoon_unfiltered} and
\ref{fig:ipdcartoon_filtered}, we have plotted a schematic of the
trace signal. In this figure all pulses have the same magnitude for
simplicity, and indeed we will focus about the distributions of
durations for incorporation (pulse width) and translocation (IPD). In
the aforementioned figures, we have drawn a red arrow to indicate the
IPD at a position of interest. Each read covering a region gives us
information about the incorporation events. We can compare that to a
control sample where we are certain there are no modifications.

We want to examine the various sources of variation in the IPD and
pulse width distributions. In our case, we will compare a function of
the IPD distribution in a treatment sample (where we believe there to
be modifications) to that of a control sample (where we have removed
them). In general, we might wish to investigate whether it is possible
to determine a modification without a control sample, however, for the
remainder of this document we will be focused on the two-sample setup.
\begin{figure}[H]
  \centering
<<fig=TRUE, echo=FALSE, results=hide>>=
plotIPDForReads(cmpH5, idx = 1:100, range = c(40, 50), maxReads = 5, matches = FALSE)
@ 
\caption{{\em Trace Cartoon} - Here we plot ``trace'' views directly
  from the cmp.h5 file. When we allow the possibility of
  insertions/deletions/mismatches it is more complicated to ensure
  that you are viewing a proper incorporation event.  }
\label{fig:ipdcartoon_unfiltered}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE, echo=FALSE, results=hide>>=
plotIPDForReads(cmpH5, idx = 1:100, range = c(40, 50), maxReads = 5, matches = TRUE)
@ 

\caption{{\em Trace Cartoon} - Here we plot ``trace'' views directly
  from the cmp.h5 file. This is the same plot as above, however we are
  restricting things to those bases which match. In practice, such a
  filtering might be too stringent.  }
\label{fig:ipdcartoon_filtered}
\end{figure}

<<LoadInCmpH5s, echo=FALSE>>=
cmpH5s <- lapply(Sys.glob("../Data/Lambda/*/data/aligned_reads.cmp.h5"), PacBioCmpH5)
names(cmpH5s) <- sapply(cmpH5s, function(h) basename(dirname(dirname(h@fileName))))
@ 

\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}[H]
  \centering
  \subfloat[][]{
<<echo=FALSE,fig=TRUE>>=
plotDensity(lapply(cmpH5s, function(cmpH5) {
  v <- getIPD(cmpH5, sample(1:nrow(cmpH5), size = 100))
  do.call(c, v)
}), legend = T, log = 'x', xlab = "IPD")
@
}
  \subfloat[][]{
<<echo=FALSE,fig=TRUE>>=
plotDensity(lapply(cmpH5s, function(cmpH5) {
  v <- getPulseWidth(cmpH5, sample(1:nrow(cmpH5), size = 100))
  do.call(c, v)
}), legend = T,  log = 'x', xlab = "Pulse Width")
@
}
  \caption{{\em Global IPD and PulseWidth Densities} - Here we plot
    the global IPD and PulseWidth distributions. This distribution is
    a mix of incorporations of the 4 nucleotides. Both IPD and
    PulseWidth are currently stored in the file in seconds rather than
    frames. The spikes occur because in fact the distribution is not
    continuous.  }
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat[][]{
<<echo=FALSE,fig=TRUE>>=
l <- lapply(cmpH5s, function(cmpH5) {
  w <- sample(1:nrow(cmpH5), size = 1000)
  v <- do.call(c, getIPD(cmpH5, w))
  a <- do.call(c, lapply(getAlignments(cmpH5, w), function(b) b[,1]))
  split(v, factor(a, c("A","C","G","T")))
})
show(ggplot(melt(l), aes(x = L2, y = value, color = L1)) + geom_boxplot(outlier.shape = NA) + 
     scale_y_continuous(limits = c(0, .4)) + xlab("Base") + ylab("IPD") + 
     opts(title="IPD by Base"))
@ 
}
  \subfloat[][]{
<<echo=FALSE,fig=TRUE>>=
l <- lapply(cmpH5s, function(cmpH5) {
  w <- sample(1:nrow(cmpH5), size = 1000)
  v <- do.call(c, getPulseWidth(cmpH5, w))
  a <- do.call(c, lapply(getAlignments(cmpH5, w), function(b) b[,1]))
  split(v, factor(a, c("A","C","G","T")))
})
show(ggplot(melt(l), aes(x = L2, y = value, color = L1)) + geom_boxplot(outlier.shape = NA) + 
     scale_y_continuous(limits = c(0, .5)) + xlab("Base") + ylab("PulseWidth") + 
     opts(title="PulseWidth by Base"))
@ 
}
\caption{{\em IPD and PulseWidth By Base} - Here we plot the IPD and
  PulseWidth distributions stratified by the base being
  incorporated. We see that there is a base effect on IPD, i.e., which
  base we are incorporating changes the kinetic behavior of the
  enzyme.  }
\end{figure}
\setkeys{Gin}{width=0.8\textwidth}

The \RFunction{getByTemplatePosition} function retrieves data for
\RCode{idx} reads. It takes a function, $f$, which returns a list of
vectors or matrices where the length or number of rows is equal to the
alignment length for alignment $i$. Typically, one just passes in an
existing function, such as \RFunction{getIPD} or
\RFunction{getPulseWidth}.
<<echo=TRUE>>=
head(getByTemplatePosition(cmpH5, idx = 1:2, f = getIPD))
@ 
Additionally, there are a number of high-level data access functions
related to retrieving the information in the cmp.h5 file by position
and context. As mentioned before, these functions take a vector of
indices which refer to the reads in the alignment index to be used,
e.g.,
<<echo=TRUE>>=
head(makeContextDataTable(cmpH5, idx = 1:2, up = 2, down = 2))
@ 
Another useful function for summarizing things by context is:
<<echo=TRUE>>=
s <- summarizeByContext(cmpH5, idx = 1:100, up = 1, down = 1, statF = getPulseWidth)
head(s)
@ 
Throughout this document we will be using these two or three functions
for data access. Below we define a convenience function which takes a
range along the genome and then retrieves the results of $f$ for those
reads. An important point to notice is that the
\RFunction{getReadsInRange} function returns any read that overlaps
either the start or the end of the range. Therefore, portions of reads
will not be within $[s, e]$, hence the subset below.
<<echo=TRUE>>=
getByPositionAndStrand <- function(f = getIPD, s = 20000, e = 20025) {
  pbutils::collapse(lapply(cmpH5s, function(cmpH5) {
    x <- getByTemplatePosition(cmpH5, idx = getReadsInRange(cmpH5, 1, s, e), f = f)
    x <- subset(x, position >= s & position <= e)
    ddply(x, c("strand", "position"), function(a) {
      median(a$elt, na.rm = T)
    })
  }))
}             
byPositionAndStrandIPD <- getByPositionAndStrand()
byPositionAndStrandPW <- getByPositionAndStrand(f=getPulseWidth)
@ 

\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}[H]
  \centering
  \subfloat[][]{
<<fig=TRUE,echo=FALSE>>=
show(ggplot(byPositionAndStrandIPD, aes(x = position, y = V1, color = factor(strand), lty = L1, 
                                        group = factor(strand):factor(L1))) +
     geom_line() + ylab("Median IPD"))
@ 
}
  \subfloat[][]{
<<fig=TRUE,echo=FALSE>>=
show(ggplot(byPositionAndStrandPW, 
            aes(x = position, y = V1, color = factor(strand), lty = L1, 
                group = factor(strand):factor(L1))) +
     geom_line() + ylab("Median Pulse Width"))
@ 
}
  \caption{{\em IPD and PulseWidth by Strand and Position} - Here we plot the median of the IPD
    distribution conditioned on both strand and position. We can see the
    presence of a very strong position and strand effect.
  }
\end{figure}
\setkeys{Gin}{width=0.8\textwidth}

\subsection{Context-specific Efffects}
Finally, we investigate the effect of sequence context on IPD and
pulse width distributions. Alignment-level data from a cmp.h5 file is
always stored with respect to the bases being incorporated. Therefore,
when one retrieves an alignment from the cmp.h5 file, if that
alignment is labeled as a reverse strand alignment:
\RCode{getTemplateStrand(cmpH5) == 1}, then the
reference sequence is reverse complemented rather than the read. The
importance of this representation is that we always store the data
(e.g., alignments, IPDs, pulse widths, etc.) in the direction in which
the bases are incorporated. 
\begin{figure}[H]
  \centering
  \includegraphics[width=2.5in,height=2.5in]{Pol2Graphic}
  \caption{{\em GATC Cartoon} - A cartoon depicting the incorporation
    of ``T'' which will be ``delayed'' when the complement A base is
    methylated. The ``T'' base is what is stored in the ``AlnArray''
    data structures. 
  }
\end{figure}
<<echo=TRUE>>=
getTemplateStrand(cmpH5)[1:10]
tmp <- getByTemplatePosition(cmpH5, idx = 1:2)
head(tmp[order(tmp$position, tmp$strand),])
@ 
We can use the \RFunction{associateWithContext} to get a data element
by context. There are a couple of relevant options to consider. First,
context can either be determined by the read bases or by the reference
bases. In either case, gaps are removed from either the read or the
reference and then context is computed. 
<<echo=TRUE>>=
tmp <- associateWithContext(cmpH5, idx = 1:2, f = getTemplatePosition, collapse = T, 
                            useReference = T)
head(tmp[order(tmp$elt),])
@ 
Here we used the reference context to group the results of the
function call $f$ and you can see that there are two different
contexts for the same position (the results of $f$ is stored in the
column with name ``elt'') -- this occurs because we still maintain the
orientation of the alignments in terms of read space, so for the
reference context of 'GGGCG' there are the set of reverse strand reads
with the context 'CGCCC'.
\begin{figure}[H]
  \centering
<<fig=TRUE,echo=TRUE>>=
contextTable <- associateWithContext(cmpH5, idx = sample(1:nrow(cmpH5), size = 1000), f = getIPD, 
                                     collapse = T, useReference = T, up = 1, down = 1)
par(cex.axis = .65)
boxplot(split(contextTable$elt, contextTable$context), ylim = c(0, .5), las = 2, 
        main = "Context-specific IPD distributions", ylab = "IPD", outline = FALSE, 
        col = rep(1:4, each = 4))
@ 
\caption{{\em IPD by Context} - Plots of IPD by context. We can see
  that the IPD distribution depends on context. Here the boxplots have
  been colored by the base being incorporated.}
\end{figure}
We can use the \RFunction{associateWithContext} to see modification
patterns which might follow motifs, rather than specific positions. In
this case, we focus on the DAM+ condition of the Lambda dataset as
GATC motif is mostly modified.
\begin{figure}[H]
  \centering
<<fig=TRUE, echo=FALSE, results=hide>>=
par(mfrow=c(2,1), mar = c(3, 5, 1, 1))
lapply(cmpH5s[c("6mA_dam+_native", "6mA_dam-_native")], function(cmp) {
  tmp <- associateWithContext(cmp, idx = sample(1:nrow(cmp), size = 5000), 
                              f = getIPD, collapse = T, useReference = T, up = 2, down = 2)
  contextMedians <- tapply(tmp$elt, tmp$context, median, na.rm = T)
  plot(x <- 1:length(contextMedians), y <- contextMedians, pch = 16, 
       ylim = c(0, 1), xlab = "Context", xaxt = 'n', ylab = "Median")
  w <- grep("^GATC", names(y))
  text(x[w], y[w], names(y)[w], col = "darkblue", cex = 1.3)
})
@ 
\caption{{\em Context-specific Modifications} -- Here we plot the
  median IPD for 5 based contexts for both the DAM+ and DAM- Lambda
  strains. First, the range of IPDs is quite similar for all
  non-modified motifs, i.e., the motif effect is larger than the the
  strain effect - this will be clearer when we directly compare the
  IPD measurements across sample. 
}\label{fig:contextspecificmods}
\end{figure}


\section{Statistical Testing}
In this section we focus on two-sample statistical tests comparing the
IPD distribution in a control sample to a treatment. Each particular
DNA modification has a different signature at or around the modified
base and more sophisticated methods will take that into account. In
this section, we will first focus on the Synthetic data sets where the
modified positions are known. Here, we will look at detection as a
function of coverage. In general, with sufficient coverage the
difference between IPD distributions can be detected, however, certain
modifications do not have a large effect on the kinetics of the
polymerase and therefore to detect these smaller effects we need to
observe the incorporation event many times. Additionally, the effects
of a modified base might occur around the actual modifications as
opposed to the exact methylated site.

We can view this as a simple two-sample statistical testing problem
where IPD measurements obtained from our native sample are compared to
IPD measurements obtained from an unmodified sample. As in many
high-throughput sequencing experiments, some of the canonical
assumptions, e.g., independence, normality, etc. might not be
satisfied. In addition, one necessarily cares about multiple testing
as there are many sites to test. At the end of this section we will
discuss natural enhancements to the simple procedures demonstrated
here.

Before we begin to analyze the modification signal for the Synthetic
template data, it is important to understand the topology of the
synthetic molecule. The sequence which we align to is a reverse
complement of itself with a hairpin at one end and a Smrtbell at the
other end. In the default pipeline, the Smrtbell is found and the reads
are partitioned into individual ``subreads'' based on that adapter
location. Due to the shortness of the reference sequence which we
align to there are some ``edge effects'' - we can see this in Figure
\ref{fig:syntheticcoverage}, where the coverage tails off dramatically
at the ends of the sequence.
<<>>=
cmpH5s <- lapply(Sys.glob("../Data/Synthetic/*/data/aligned_reads.cmp.h5"), PacBioCmpH5)
names(cmpH5s) <- sapply(cmpH5s, function(h) basename(dirname(dirname(h@fileName))))
modifications <- list("2x_5mC"  = c(55,74),
                      "2x_5hmC" = c(51,74),
                      "2x_4mC"  = c(55,74),
                      "2x_6mA"  = c(57,68,112,123))
syntheticStart <- 20
syntheticEnd <- 150

distributionPlot <- function(positions, nm) {
  getIPDForPosition <- function(p) {
    lapply(cmpH5s[c(nm, "control")], function(cmpH5) {
      subset(getByTemplatePosition(cmpH5, idx = sample(1:nrow(cmpH5), size = 5000)), 
             position == p & strand == 0 & read == ref)$elt
    })
  }
  par(mfrow=c(length(positions), 2), mar = c(5, 5, 4, 1))
  lapply(positions, function(z) {
    title <- paste("Position:", z)
    lst <- lapply(getIPDForPosition(z), function(k) log10(k+1/76))
    plotDensity(lst, legend = TRUE, main = title, xlab = "Started log10 of IPD")
    qqPairs(lst, main = title)
  })
}
@
\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide>>=
matplot(sapply(cmpH5s, getCoverageInRange, refSeq = 1), type = 'l', ylab = "coverage", xlab = "position")
legend("topleft", names(cmpH5s), fill = 1:length(cmpH5s), bg = 'white')
@ 
\caption{{\em Coverage Across Synthetic Reference} - Here we plot the
  ``pileup'' coverage across the synthetic template. We can see the
  extreme dropoff of coverage towards the ends of the sequence.
}\label{fig:syntheticcoverage}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide>>=
distributionPlot(c(modifications[["2x_6mA"]][1], 40), "2x_6mA")
@ 
\caption{{\em Density at position and Strand} - Here we plot the
  IPD distribution for both a truly modified site as well as a
  non-modified site. We can see that there is a very large effect on
  the distribution when the modification is a methyl-A.
}\label{fig:testing1}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide>>=
distributionPlot(c(modifications[["2x_5mC"]][1], 40), "2x_5mC")
@ 
\caption{{\em Density at position and Strand} - Here we plot the
  IPD distribution for both a truly modified site as well as a
  non-modified site. We can see that the effect on IPD is much smaller
  when the modification is a methyl-C indicating that we will need
  larger sample sizes to obtain the same precision as a methyl-A.
}\label{fig:testing2}
\end{figure}
As Figures \ref{fig:contextspecificmods}, \ref{fig:testing1}, and
\ref{fig:testing2} demonstrate, a natural statistic when comparing the
IPDs of a control sample to a treatment sample is the mean ratio,
either logged or unlogged. We sometimes refer to the following
statistic $S$ as the IPD ratio:
\begin{equation}
  S = \frac{1/N_{treatment}\sum_{i = 1}^{N_{treatment}} IPD_{i, treatment}}{1/N_{control}\sum_{i = 1}^{N_{control}} IPD_{i, control}}
\end{equation}
Here $S$ is specific to a particular reference position, and
$N_{treatment}$ corresponds to the number of IPD events at that
position in the treatment sample. In Figure \ref{fig:ipdratios}, we
plot $S$ as defined above for the four methylated synthetic templates.
\begin{figure}[H]
  \centering
<<fig=TRUE, results=hide>>=
getIPDRatios <- function() {
  getIPDMeanByPosition <- function(cmpH5) {
    s <- subset(getByTemplatePosition(cmpH5, idx = sample(1:nrow(cmpH5), size = 5000)), 
                read == ref)
    tapply(s$elt, factor(s$position, 1:getRefLength(cmpH5, 1)), mean, na.rm = T)
  }
  ctrl <- getIPDMeanByPosition(cmpH5s[["control"]])
  lapply(cmpH5s[names(cmpH5s) != "control"], function(cmpH5) {
    getIPDMeanByPosition(cmpH5)/ctrl
  })
}
ipdRatios <- getIPDRatios()
par(mfrow=c(4,1), mar = c(4, 4, 3, 1))
lapply(names(ipdRatios), function(a) {
  plot(ipdRatios[[a]], pch = 16, xlab = "Position",  ylim = c(0, 8), ylab = "IPD Ratio", main = a, 
       xlim = c(syntheticStart, syntheticEnd))
  abline(v = modifications[[a]], col = "grey", lwd = 4)
  points(ipdRatios[[a]], pch = 16)
})
@ 
\caption{{\em IPD Ratios} - Here we plot the IPD ratio statistic. This
  statistic is a measure of the mean shift in IPD
  distributions. One pertinent aspect of the IPD data that this plot
  shows is the different signatures for a given modification.
}\label{fig:ipdratios}
\end{figure}

\subsection{Testing by Coverage}
Naturally, we generally want more than just an IPD ratio, or measure
of the difference between two distrubtions, we want to know whether
that difference would have been likely to be observed by chance. As is
clear from Figure \ref{fig:ipdratios}, the different modifications
have dramatically different signals and effect sizes. Below we
investigate the performance of a Wilcox test when making the
comparison for increasingly larger amounts of coverage. The Wilcox
test is general and robust and does not depend on a particular form of
the distribution. Where site-wise statistical testing becomes more
subtle is the independence assumption between sites (i.e., position 10
and 11 contain a large number of common reads) as well as the
independence assumption within molecule. Both of these assumptions
need to be addressed when correcting for multiple testing. 

<<TestPositions, eval=TRUE, echo=FALSE>>=
COVGS <- c(c10 = 10, c50 = 50, c100 = 100, c500 = 500, c1000 = 1000)

testPositions <- function(treatmentH5, controlH5, testStatistic = wilcox.test, 
                          targetStrands = c(0, 1), targetPositions = NA, 
                          targetCoverage = COVGS, throwOutFirstSubread = TRUE,
                          getData = getByTemplatePosition, whReference = 1) {
  if (any(is.na(targetPositions))) {
    start <- 1
    end <- refInfo(controlH5)$Length[whReference]
  } else {
    start <- min(targetPositions)
    end <- max(targetPositions)
  }
  ## find which reads to grab and then possibly downsample. 
  tReads <- getReadsInRange(treatmentH5, whReference, start, end)
  cReads <- getReadsInRange(controlH5, whReference, start, end)

  if (throwOutFirstSubread) {
    rlowest <- function(h5, r) {
      do.call(c, lapply(split(r, getMoleculeIndex(h5)[r]), function(i) {
        i[-which.min(h5$rStart[i])]
      }))
    }
    tReads <- rlowest(treatmentH5, tReads)
    cReads <- rlowest(controlH5, cReads)
  }
  
  ## retrieve the data as a data.frame.
  tData <- getData(treatmentH5, idx = tReads)
  cData <- getData(controlH5, idx = cReads)

  ## filter the data.
  tData <- subset(tData, (strand %in% targetStrands) & (position >= start & position <= end) & read == ref)
  cData <- subset(cData, (strand %in% targetStrands) & (position >= start & position <= end) & read == ref)
    
  g <- function(v, n) {
    if (length(v) > n) sample(v, size = n) else v
  }
  mapply(function(tIdxs, cIdxs) {
    lapply(targetCoverage, function(n) {
      testStatistic(tData$elt[g(tIdxs, n)], cData$elt[g(cIdxs, n)])
    })
  }, split(1:nrow(tData), factor(tData$position, start:end)), 
         split(1:nrow(cData), factor(cData$position, start:end)), SIMPLIFY = FALSE)
}

plotResult <- function(nm, g = function(z) -log10(z$p.value), ...) {
  tp <- testResults[[nm]]
  modifiedPositions <- modifications[[nm]]
  par(mfrow=c(5,1), mar = c(2, 2, 1, 1))
  sapply(1:5, function(i) {
    positions <- as.integer(names(tp))
    y <- sapply(tp, function(x) g(x[[i]]))
    plot(positions, y, xlab = "", ylab = "", 
         main = paste("-log10 p-values for coverage:", names(tp[[1]])[i], "(", nm, ")"),
         pch = 16, cex = 1.25)
    abline(v = modifiedPositions, col = 'grey', lty = 3)
  })
}
testResults <- lapply(cmpH5s[1:4], function(tH5) {
  testPositions(tH5, cmpH5s$control, targetStrands = 0)
})
@ 
\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
plotResult("2x_6mA")
@ 
\caption{Here we plot the $-\log_{10}$ p-values from the Wilcox test
  for increasing levels of coverage for the 2x\_6mA modified template.}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
plotResult("2x_4mC")
@ 
\caption{Here we plot the $-\log_{10}$ p-values from the Wilcox test
  for increasing levels of coverage for the 2x\_4mC modified template.}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
plotResult("2x_5hmC")
@ 
\caption{Here we plot the $-\log_{10}$ p-values from the Wilcox test
  for increasing levels of coverage for the 2x\_5hmC modified template.}
\end{figure}

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
plotResult("2x_5mC")
@ 
\caption{Here we plot the $-\log_{10}$ p-values from the Wilcox test
  for increasing levels of coverage for the 2x\_5mC modified template.}
\end{figure}

\subsection{ROC Analysis}
In this section we evaluate the performance of 3 different statistical
tests via ROC analysis. We can determine if a particular testing
procedure outperforms another in general. Additionally, we can get a
sense of our true-positive and false-positive rates for a particular
modification. The different tests that we employ are three related
tests where each position is tested independently of the other
positions. In general, as we can see from the $-\log_{10}$ p-values by
position plots, the effect of a modification alters the IPD
distribution in nearby bases. More sophisticated tests should take
this into account.
<<DoDifferentTestProcedures, eval=TRUE, echo=FALSE>>=
doAcrossProcedures <- function(cmpH5) {
  trimmedSlog <- function(x, trim = .975, alpha = 1/100) {
    log(x[x<quantile(x, trim)] + alpha)
  }
  testFunctions <- list(wilcox.test = wilcox.test,
                        trimmed.slog.t = function(x, y) {
                          t.test(trimmedSlog(x), trimmedSlog(y))
                        }, 
                        lr.test = function(x, y) {
                          z <- c(lx <- trimmedSlog(x), ly <- trimmedSlog(y))
                          m1 <- sum(dnorm(z, mean(z), sd(z), log = T))
                          m2 <- sum(dnorm(lx, mean(lx), sd(lx), log = T)) +
                            sum(dnorm(ly, mean(ly), sd(ly), log = T))
                          stat <- -2*(m1-m2)
                          list(statistic = stat, p.value = 1-pchisq(stat, 2))
                        })
  lapply(testFunctions, function(f) {
    testPositions(cmpH5, cmpH5s$control, targetStrands = 0, testStatistic = f)
  })
}
byTestFunction <- lapply(cmpH5s[1:4], doAcrossProcedures)

plotROC <- function(nm) {
  byT <- byTestFunction[[nm]]
  truePositives <- rep(FALSE, length(byT[[1]]))
  truePositives[modifications[[nm]]] <- TRUE
  truePositives <- factor(truePositives, c(TRUE, FALSE))
  v <- c("c10"=1, "c50"=2, "c100"=3, "c500"=4, "c1000"=5)
  pbutils::collapse(lapply(v, function(i) {
    pbutils::collapse(lapply(byT, function(testRes) {
      x <- sapply(testRes, function(r) r[[i]]$p.value)
      x <- do.call(rbind, lapply(c(sort(x), Inf), function(q) {
        tbl <- table(truth = truePositives, observed = factor(x < q, c(TRUE, FALSE)))
        c(tbl[2,1]/sum(tbl[2,]), tbl[1,1]/sum(tbl[1,]))
      }))
      colnames(x) <- c("FPR", "TPR")
      return(x)
    }))
  }))
}
@ 
\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
tmp <- lapply(names(byTestFunction), plotROC)
names(tmp) <- names(byTestFunction)
tmp <- pbutils::collapse(tmp)
tmp$L2 <- factor(as.character(tmp$L2), c("c10", "c50", "c100", "c500", "c1000"))
tmp$L3 <- factor(as.character(tmp$L3), names(modifications))
show(ggplot(tmp, aes(x = as.numeric(FPR), y = as.numeric(TPR), color = L1)) + facet_grid(L3 ~ L2) + 
     geom_line(lwd = 1))
@ 
\caption{{\em ROC Curves} - Here we plot ROC curves for the three
different testing procedures faceted by coverage and modification
type. These curves demonstrate the differences in the magnitude of the
modification effects. It is clear the 6mA is quite easy to detect,
even at a relatively low level of coverage. However, it is
equivalently clear that 5mC has a much smaller effect on the IPD
distribution. 
}
\end{figure}
As we can see, the differing test procedures do not produce
dramatically different results. Indeed, we already knew we would
produce false positives in the case of the 5mC modification as its
effect on the IPD occurs three bases downstream. In any case, we can
see that at sufficient coverage our false positive/true positive
tradeoff is quite good for 5hmC, 4mC, and 6mA
modifications.

\subsection{Statistical Testing in Lambda}
<<echo=FALSE>>=
cmpH5s <- lapply(Sys.glob("../Data/Lambda/*/data/aligned_reads.cmp.h5"), PacBioCmpH5)
names(cmpH5s) <- sapply(cmpH5s, function(h) basename(dirname(dirname(h@fileName))))
@ 
As mentioned previously, a much more realistic dataset is the lambda
dataset where we have 4 distinct conditions (Table
\ref{tbl:lambda}). In this context, we have both a DAM+ and a DAM-
condition which we can compare as well as their corresponding WGA
vs. Native preparations. For simplicity, we can compare DAM+ and DAM-
and focus on GATC methylation sites as our true positives.

For this analysis, we will need to use the Biostrings package to
determine where the GATC sites are in the genome. As an example we can
look at one position.
<<echo=TRUE, results=hide>>=
if (! require(Biostrings)) {
  stop("Unable to execute Lambda testing examples without Biostrings package.")
}
lambda <- read.DNAStringSet("../ReferenceRepository/lambdaNEB/lambdaNEB.fa")[[1]]
matches <- matchPattern("GATC", lambda)
gatcExample <- pbutils::collapse(lapply(cmpH5s[c("6mA_dam+_native", "6mA_dam-_native")], function(cmp) {
  s <- start(matches)[1]
  e <- end(matches)[1]
  subset(getByTemplatePosition(cmp, idx = getReadsInRange(cmp, 1, s, e), f = getIPD),
         position >= s & position <= e & read == ref)
}))
@ 

\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
show(ggplot(gatcExample, aes(x = factor(position), y = elt, color = L1)) + geom_boxplot() + 
     facet_wrap(~ strand) + scale_y_log10())
@ 
\caption{{\em GATC modification} - At this particular GATC
  modification, we can see that there is a strong signal of the
  modification and the reference position depends on the strand. This
  indeed makes sense as the strand we report means that we had to
  reverse complement the reference sequence to match the incorporated
  bases. Said another way, the template was the forward strand of the
  reference in this instance. 
}
\end{figure}

\section{Conclusion}
This document attempts to provide a user with an overview of PacBio
data and APIs which support performing Kinetics analyses. This
document is an attempt to present the analyst with a starting point
for their kinetics analyses using Pacific Biosciences data. This
document is a ``live'' document in the sense that we will be updating
the tools presented here for more complicated analyses. For the user
who wishes to process their data in the most simplistic fashion, we
provide the following utility:
<<echo=TRUE, eval=TRUE>>=
topTable <- makeTopTable(cmpH5s[["6mA_dam+_native"]], cmpH5s[["6mA_dam-_native"]], 
                         start = 1, end = 5000)
head(topTable)
@
This utility produces a table ordered by p-value, where each row
represents a position in the reference. Users might very well like to
modify this utility function, please refer to ``utils.R'' in the
``Src'' directory of this project.
\begin{figure}[H]
  \centering
<<fig=TRUE,results=hide,echo=FALSE>>=
plot(topTable$position, -log10(topTable$fdr), pch = 16, ylab = "-log10(FDR adjusted p.values)", 
     xlab = "position", main = "-log10 FDR adjusted p.values")
abline(v = start(matches) + 1)
@ 
\caption{{\em Lambda FDR Adjusted P-values by Position} - For
  approximately 5000 bases across the Lambda genome we plot
  $-\log_{10} p$-values by position. Vertical lines indicate GATC
  positions in the genome.  }
\end{figure}

\subsection{Next Steps}
As one can see from this document there are a number of enhancements
that can be conceived of in the two-sample comparison case. First, one
might prefer a permutation test when comparing the native vs. WGA
samples. In the ``utils.R'' file there exists an example of such a
procedure. One might prefer an empirical Bayes approach when the
number of reads is low. Finally, one might wish to investigate
whether taking into account the modification signature rather than
just the individual IPD provides a substantially more powerful test
than just the individual position. 

\subsection{Session Info}
<<echo=TRUE>>=
sessionInfo()
@ 
\end{document}
